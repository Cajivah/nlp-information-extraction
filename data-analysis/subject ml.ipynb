{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from src.comparator import compare_metadata, Comparator, print_diff, print_correctly_extracted\n",
    "import src.datasets as load\n",
    "from src.kuba_information_extractor import KubaInformationExtractor\n",
    "import pprint\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "data_sets = load.load(DATA_PATH)\n",
    "\n",
    "import numpy as np  \n",
    "import re  \n",
    "from sklearn.datasets import load_files  \n",
    "import pickle  \n",
    "\n",
    "from src.morf_utils import MorfWrapper\n",
    "from src.compare_utils import deogonkify\n",
    "import morfeusz2\n",
    "\n",
    "translation = {\"room\": 1, \"roomShare\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for d in data_sets:\n",
    "    content = d[\"content\"]\n",
    "    category = d[\"meta\"][\"subject\"]\n",
    "    if category is None:\n",
    "        category = 'any'\n",
    "    X.append(content)\n",
    "    y.append(translation[category])\n",
    "    \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for sen in range(0, len(X)):  \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = load.load_stopwords();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "tfidfconverter = TfidfVectorizer(max_features=500, min_df=1, ngram_range=(1, 2), lowercase=True)  \n",
    "tfidf = tfidfconverter.fit(documents)\n",
    "\n",
    "X = tfidf.transform(documents).toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier(n_estimators=100) \n",
    "scores = cross_val_score(classifier, X, y, cv=5)\n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display (scores)\n",
    "display (scores.mean())\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  \n",
    "\n",
    "conf_matrix_df = pd.DataFrame(confusion_matrix(y_test,y_pred), \\\n",
    "                                index= [i for i in (\"a\", \"b\")], \\\n",
    "                                columns=[i for i in (\"a\", \"b\")])\n",
    "sns.heatmap(conf_matrix_df, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('subject_classifier', 'wb') as picklefile:  \n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open(\"tfidf_subject.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
