{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from src.comparator import compare_metadata, Comparator, print_diff, print_correctly_extracted\n",
    "import src.datasets as load\n",
    "from src.kuba_information_extractor import KubaInformationExtractor\n",
    "import pprint\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "data_sets = load.load(DATA_PATH)\n",
    "\n",
    "import numpy as np  \n",
    "import re  \n",
    "from sklearn.datasets import load_files  \n",
    "import pickle  \n",
    "\n",
    "from src.morf_utils import MorfWrapper\n",
    "from src.compare_utils import deogonkify\n",
    "import morfeusz2\n",
    "\n",
    "translation = {\"room\": 1, \"roomShare\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for d in data_sets:\n",
    "    content = d[\"content\"]\n",
    "    category = d[\"meta\"][\"subject\"]\n",
    "    if category is None:\n",
    "        category = 'any'\n",
    "    X.append(content)\n",
    "    y.append(translation[category])\n",
    "    \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for sen in range(0, len(X)):  \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = load.load_stopwords();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "tfidfconverter = TfidfVectorizer(max_features=500, min_df=1, ngram_range=(1, 2), lowercase=True)  \n",
    "tfidf = tfidfconverter.fit(documents)\n",
    "\n",
    "X = tfidf.transform(documents).toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  \n",
    "\n",
    "scores_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier(n_estimators=500) \n",
    "scores = cross_val_score(classifier, X, y, cv=5)\n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test) \n",
    "scores_df[\"AdaBoost\"] = scores.mean()\n",
    "display(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_by_metric = {}\n",
    "scores = {}\n",
    "for p in [5, 10, 20, 50, 75, 125, 250, 500, 1000]:\n",
    "    clf = AdaBoostClassifier(n_estimators=p)\n",
    "    score = cross_val_score(clf, X, y, scoring=\"accuracy\", cv=5)\n",
    "    scores[p] = score.mean()\n",
    "    \n",
    "scores_by_metric[f\"AdaBoost\"] = scores;\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(data=scores_by_metric)\n",
    "df.index.name = \"ada\"\n",
    "df.reset_index(level=0, inplace=True)\n",
    "print(f\"metric = asdfasdf\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train) \n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "y_pred = clf.predict(X_test)\n",
    "scores_df[\"SVC\"] = scores.mean()\n",
    "display(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "gnb = naive_bayes.BernoulliNB()\n",
    "clf = gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores_df[\"Gaussian NB\"] = scores.mean()\n",
    "display(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "best = 0.0\n",
    "best_clf = None\n",
    "for i in range(0, 200):\n",
    "    clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "#     clf = clf.fit(X_train, y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    if scores.mean() > best:\n",
    "        best = scores.mean()\n",
    "        best_clf = clf\n",
    "#     scores_df[\"Decision tree\"] = scores.mean()\n",
    "display(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5, p=2, algorithm=\"brute\")\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, scoring=\"accuracy\", cv=5)\n",
    "scores_df[\"kNN\"] = scores.mean()\n",
    "display(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_by_metric = {}\n",
    "for p in range(1, 5):\n",
    "    scores = {}\n",
    "    for k in range(1,21):\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, p=p)\n",
    "        score = cross_val_score(clf, X, y, scoring=\"accuracy\", cv=5)\n",
    "        scores[k] = score.mean()\n",
    "    scores_by_metric[f\"minkowski-{p}\"] = scores;\n",
    "    \n",
    "\n",
    "scores = {}\n",
    "for k in range(1,21):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, metric='chebyshev')\n",
    "    score = cross_val_score(clf, X, y, scoring=\"accuracy\", cv=5)\n",
    "    scores[k] = score.mean()\n",
    "scores_by_metric[f\"chebyshev\"] = scores;\n",
    "    \n",
    "df = pd.DataFrame(data=scores_by_metric)\n",
    "df.index.name = \"n_neighbors\"\n",
    "df.reset_index(level=0, inplace=True)\n",
    "print(f\"metric = asdfasdf\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  \n",
    "\n",
    "conf_matrix_df = pd.DataFrame(confusion_matrix(y_test,y_pred), \\\n",
    "                                index= [i for i in (\"miejsce w pokoju\", \"pokoj\")], \\\n",
    "                                columns=[i for i in (\"miejsce w pokoju\", \"pokoj\")])\n",
    "sns.heatmap(conf_matrix_df, annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, df in df_by_metric.items():\n",
    "    df_for_plot = pd.melt(df, \"n_neighbors\", var_name=\"dataset\", value_name=\"score\")\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    sns.swarmplot(x=\"n_neighbors\", y=\"score\", hue=\"dataset\", data=df_for_plot)\n",
    "    plt.savefig(f\"plots/knn-acc-{metric}.eps\", format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classifier_subject.pickle', 'wb') as picklefile:  \n",
    "    pickle.dump(best_clf, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open(\"tfidf_subject.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(conf_matrix_df, annot=True).get_figure().savefig(\"bern.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
